{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2         3         4         5         6    7    8    9    \\\n",
      "0        0    0    0  0.000066  0.000066  0.009150  0.009150    0    0    0   \n",
      "1        0    0    0  0.000014  0.000014  0.000000  0.000000    0    0    0   \n",
      "2        0    0    0  0.035528  0.035528  0.070588  0.070588    0    0    0   \n",
      "3        0    0    0  0.005128  0.005128  0.094771  0.094771    0    0    0   \n",
      "4        0    0    0  0.035116  0.035116  0.070588  0.070588    0    0    0   \n",
      "...    ...  ...  ...       ...       ...       ...       ...  ...  ...  ...   \n",
      "97039    0    0    0  0.035953  0.035953  0.038562  0.038562    0    0    0   \n",
      "97040    0    0    0  0.018075  0.018075  0.038562  0.038562    0    0    0   \n",
      "97041    0    0    0  0.041889  0.041889  0.038562  0.038562    0    0    0   \n",
      "97042    0    0    0  0.004191  0.004191  0.038562  0.038562    0    0    0   \n",
      "97043    0    0    0  0.002892  0.002892  0.038562  0.038562    0    0    0   \n",
      "\n",
      "       ...  143  144  145  146  147  148  149  150  151  152  \n",
      "0      ...  0.0    0    0    0    0    0    0    0  0.0    0  \n",
      "1      ...  0.0    0    0    0    0    0    0    0  0.0    0  \n",
      "2      ...  0.0    0    0    0    0    0    0    0  0.0    0  \n",
      "3      ...  0.0    0    0    0    0    0    0    0  0.0    0  \n",
      "4      ...  0.0    0    0    0    0    0    0    0  0.0    0  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "97039  ...  0.0    0    0    0    0    0    0    0  0.0    1  \n",
      "97040  ...  0.0    0    0    0    0    0    0    0  0.0    1  \n",
      "97041  ...  0.0    0    0    0    0    0    0    0  0.0    1  \n",
      "97042  ...  0.0    0    0    0    0    0    0    0  0.0    1  \n",
      "97043  ...  0.0    0    0    0    0    0    0    0  0.0    1  \n",
      "\n",
      "[97044 rows x 153 columns]\n"
     ]
    }
   ],
   "source": [
    "### ALL GROUP MEMBERS - Pre-processing ###\n",
    "\n",
    "# Load Data\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "file_path = 'datasets/train_imperson_without4n7_balanced_data.csv'\n",
    "\n",
    "# Read data removing the first row that is a header as numbers\n",
    "data = read_csv(file_path, header=None, skiprows=1)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            3         4         5         6    11   12   13   14   15   17   \\\n",
      "0      0.000066  0.000066  0.009150  0.009150    1    1    1    1    1    1   \n",
      "1      0.000014  0.000014  0.000000  0.000000    1    1    1    1    1    1   \n",
      "2      0.035528  0.035528  0.070588  0.070588    1    1    1    1    1    1   \n",
      "3      0.005128  0.005128  0.094771  0.094771    1    1    1    1    1    1   \n",
      "4      0.035116  0.035116  0.070588  0.070588    1    1    1    1    1    1   \n",
      "...         ...       ...       ...       ...  ...  ...  ...  ...  ...  ...   \n",
      "97039  0.035953  0.035953  0.038562  0.038562    1    1    1    1    1    1   \n",
      "97040  0.018075  0.018075  0.038562  0.038562    1    1    1    1    1    1   \n",
      "97041  0.041889  0.041889  0.038562  0.038562    1    1    1    1    1    1   \n",
      "97042  0.004191  0.004191  0.038562  0.038562    1    1    1    1    1    1   \n",
      "97043  0.002892  0.002892  0.038562  0.038562    1    1    1    1    1    1   \n",
      "\n",
      "       ...  136  137  138  139  140  141  142  143  151  152  \n",
      "0      ...    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0  \n",
      "1      ...    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0  \n",
      "2      ...    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0  \n",
      "3      ...    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0  \n",
      "4      ...    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "97039  ...    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    1  \n",
      "97040  ...    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    1  \n",
      "97041  ...    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    1  \n",
      "97042  ...    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    1  \n",
      "97043  ...    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    1  \n",
      "\n",
      "[97044 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "### ALL GROUP MEMBERS - Pre-processing ###\n",
    "\n",
    "# Clean Data\n",
    "\n",
    "# Remove columns where mean is zero\n",
    "data = data.loc[:, (data != 0).any(axis = 0)]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALL GROUP MEMBERS - Pre-processing ###\n",
    "\n",
    "# Separate Input and Output Data\n",
    "\n",
    "data_array = data.values\n",
    "\n",
    "input_data = data_array[:,0:80]\n",
    "output_data = data_array[:,80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.422e-05 6.422e-05 9.150e-03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [1.169e-05 1.169e-05 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [3.631e-02 3.631e-02 7.059e-02 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [4.281e-02 4.281e-02 3.856e-02 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [4.281e-03 4.281e-03 3.856e-02 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [2.953e-03 2.953e-03 3.856e-02 ... 0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "### ALL GROUP MEMBERS - Pre-processing ###\n",
    "\n",
    "# Rescale Data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import set_printoptions\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_data = min_max_scaler.fit_transform(input_data)\n",
    "\n",
    "# Summarize transformed data\n",
    "set_printoptions(precision = 3)\n",
    "print(rescaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.398 -0.398 -0.521 -0.521  0.015  0.015  0.015  0.     0.015  0.015\n",
      "   0.015  0.015 -3.143  0.015  1.569  0.015 -1.533  1.534  0.015  0.709\n",
      "   0.015  0.641  0.594 -0.175 -0.412 -0.285  1.391 -0.032 -1.542  0.02\n",
      "  -0.103 -0.163 -0.036 -0.138  0.03   2.654 -0.005 -0.008 -0.009 -0.006\n",
      "   0.015 -0.308 -0.237 -0.17  -0.003 -0.306 -0.059 -0.005 -0.029 -0.151\n",
      "  -0.294 -0.061 -0.257 -0.021 -0.069 -0.006 -0.007 -0.315 -0.029 -0.295\n",
      "  -0.068 -0.183 -0.025 -0.039 -0.148 -0.148 -0.147 -0.148 -0.148 -0.003\n",
      "  -0.003  0.    -1.05  -0.104 -0.996 -0.092 -0.026 -0.453 -0.453 -0.496]]\n"
     ]
    }
   ],
   "source": [
    "### ALL GROUP MEMBERS - Pre-processing ###\n",
    "\n",
    "# Standardize Data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard_scaler = StandardScaler().fit(rescaled_data)\n",
    "standardized_data = standard_scaler.transform(rescaled_data)\n",
    "\n",
    "# Summarize standardized data\n",
    "set_printoptions(precision = 3)\n",
    "print(standardized_data[0:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.500e-05 1.500e-05 2.138e-03 2.138e-03 2.336e-01 2.336e-01 2.336e-01\n",
      "  0.000e+00 2.336e-01 2.336e-01 2.336e-01 2.336e-01 9.225e-02 2.336e-01\n",
      "  2.072e-01 2.308e-01 0.000e+00 2.336e-01 2.336e-01 1.645e-01 2.336e-01\n",
      "  1.911e-01 2.336e-01 7.188e-02 1.168e-01 0.000e+00 2.336e-01 0.000e+00\n",
      "  0.000e+00 7.089e-04 2.656e-04 2.995e-03 3.385e-04 3.379e-04 6.390e-04\n",
      "  2.211e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.336e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "### ALL GROUP MEMBERS - Pre-processing ###\n",
    "\n",
    "# Normalize Data\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer().fit(rescaled_data)\n",
    "normalized_data = normalizer.transform(rescaled_data)\n",
    "\n",
    "# Summarize normalized data\n",
    "set_printoptions(precision = 3)\n",
    "print(normalized_data[0:1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.009 0.009 0.887 ... 0.    0.    0.   ]\n",
      " [0.    0.    0.434 ... 0.    0.    0.   ]\n",
      " [0.071 0.071 0.    ... 0.    0.    0.   ]\n",
      " ...\n",
      " [0.039 0.039 0.    ... 0.    0.    0.   ]\n",
      " [0.039 0.039 0.    ... 0.    0.    0.   ]\n",
      " [0.039 0.039 0.    ... 0.    0.    0.   ]]\n",
      "[[0.002 0.002 0.207 ... 0.    0.    0.   ]\n",
      " [0.    0.    0.11  ... 0.    0.    0.   ]\n",
      " [0.016 0.016 0.    ... 0.    0.    0.   ]\n",
      " ...\n",
      " [0.009 0.009 0.    ... 0.    0.    0.   ]\n",
      " [0.009 0.009 0.    ... 0.    0.    0.   ]\n",
      " [0.009 0.009 0.    ... 0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "### NAHOM - Selecting features ###\n",
    "\n",
    "# Feature Selection - Univariate method\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "select_k_best = SelectKBest(score_func = chi2, k = 20)\n",
    "selected_k_best_raw_data = select_k_best.fit(input_data, output_data)\n",
    "selected_k_best_normalized_data = select_k_best.fit(normalized_data, output_data)\n",
    "\n",
    "univariate_selection_raw_data_result = selected_k_best_raw_data.transform(input_data)\n",
    "univariate_selection_normalized_data_result = selected_k_best_normalized_data.transform(normalized_data)\n",
    "\n",
    "# Summarize scores\n",
    "set_printoptions(precision = 3)\n",
    "print(univariate_selection_raw_data_result)\n",
    "print(univariate_selection_normalized_data_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NAHOM - Selecting features ###\n",
    "\n",
    "# Feature Selection - RFE method\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 20)\n",
    "rfe_data = rfe.fit(input_data, output_data)\n",
    "\n",
    "# Summarize scores\n",
    "print(\"Num Features: %d\" % rfe_data.n_features_)\n",
    "print(\"Selected Features: %s\" % rfe_data.support_)\n",
    "print(\"Feature Ranking: %s\" % rfe_data.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Raw Data: 94.7% (0.102)\n",
      "Accuracy with Standardized Data: 94.5% (0.106)\n",
      "Accuracy with Normalized Data: 95.8% (0.084)\n",
      "Accuracy with K best features selected from Raw Data: 95.6% (0.078)\n",
      "Accuracy with K best features selected from Normalized Data: 95.3% (0.092)\n"
     ]
    }
   ],
   "source": [
    "### LIUTAURAS VILDA - Exploring and selecting ML algorithms ###\n",
    "\n",
    "# Trying various datasets: [1]raw, [2]standardized, [3]normalized, [4]k best features selected\n",
    "# In order to define, which fits the best and contributes mostly to algorithm's accuracy\n",
    "# Trying with LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "\n",
    "raw_data_result = cross_val_score(model, input_data, output_data, cv=kfold, scoring=scoring) # Accuracy: 0.947 (0.102)\n",
    "standardized_data_result = cross_val_score(model, standardized_data, output_data, cv=kfold, scoring=scoring) # Accuracy: 0.945 (0.106)\n",
    "normalized_data_result = cross_val_score(model, normalized_data, output_data, cv=kfold, scoring=scoring) # Accuracy: 0.958 (0.084)\n",
    "k_best_selected_raw_data_result = cross_val_score(model, univariate_selection_raw_data_result, output_data, cv=kfold, scoring=scoring) # Accuracy: 0.956 (0.067)\n",
    "k_best_selected_normalized_data_result = cross_val_score(model, univariate_selection_normalized_data_result, output_data, cv=kfold, scoring=scoring) # Accuracy: 0.953 (0.092)\n",
    "\n",
    "print(\"Accuracy with Raw Data: %.1f%% (%.3f)\" % (raw_data_result.mean() * 100, raw_data_result.std()))\n",
    "print(\"Accuracy with Standardized Data: %.1f%% (%.3f)\" % (standardized_data_result.mean() * 100, standardized_data_result.std()))\n",
    "print(\"Accuracy with Normalized Data: %.1f%% (%.3f)\" % (normalized_data_result.mean() * 100, normalized_data_result.std()))\n",
    "print(\"Accuracy with K best features selected from Raw Data: %.1f%% (%.3f)\" % (k_best_selected_raw_data_result.mean() * 100, k_best_selected_raw_data_result.std()))\n",
    "print(\"Accuracy with K best features selected from Normalized Data: %.1f%% (%.3f)\" % (k_best_selected_normalized_data_result.mean() * 100, k_best_selected_normalized_data_result.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.4% (0.031)\n",
      "Accuracy: 99.0% (0.020)\n"
     ]
    }
   ],
   "source": [
    "### LIUTAURAS VILDA - Exploring and selecting ML algorithms ###\n",
    "\n",
    "# For a second iteration trying further two best datasets: [1]univariate_selection_input_data_result, [2]univariate_selection_normalized_data_result\n",
    "# Trying with KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = KNeighborsClassifier()\n",
    "scoring = 'accuracy'\n",
    "\n",
    "k_best_selected_raw_data_result = cross_val_score(model, univariate_selection_raw_data_result, output_data, cv=kfold, scoring=scoring) # Accuracy: 98.4% (0.031)\n",
    "k_best_selected_normalized_data_result = cross_val_score(model, univariate_selection_normalized_data_result, output_data, cv=kfold, scoring=scoring) # Accuracy: 99.0% (0.020)\n",
    "\n",
    "print(\"Accuracy: %.1f%% (%.3f)\" % (k_best_selected_raw_data_result.mean() * 100, k_best_selected_raw_data_result.std()))\n",
    "print(\"Accuracy: %.1f%% (%.3f)\" % (k_best_selected_normalized_data_result.mean() * 100, k_best_selected_normalized_data_result.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Classification Algorithms Accuracy ###\n",
      "\n",
      "Logistic Regression: 95.3% (std: 0.092), runtime: 3.1s\n",
      "Linear Discriminant: 94.7% (std: 0.111), runtime: 3.2s\n",
      "k-Nearest Neighbors: 99.0% (std: 0.020), runtime: 33.1s\n",
      "Decision Trees: 96.7% (std: 0.067), runtime: 4.5s\n",
      "Naive Bayes: 96.0% (std: 0.082), runtime: 0.6s\n"
     ]
    }
   ],
   "source": [
    "### LIUTAURAS VILDA - Exploring and selecting ML algorithms ###\n",
    "\n",
    "# Potential candidate algorithms comparison\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import time\n",
    "\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Linear Discriminant', LinearDiscriminantAnalysis()))\n",
    "models.append(('k-Nearest Neighbors', KNeighborsClassifier()))\n",
    "models.append(('Decision Trees', DecisionTreeClassifier()))\n",
    "models.append(('Naive Bayes', GaussianNB()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "print(\"### Classification Algorithms Accuracy ###\\n\")\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    start_time = time.time()\n",
    "    cv_results = cross_val_score(model, univariate_selection_normalized_data_result, output_data, cv=kfold, scoring=scoring)\n",
    "    run_time = time.time() - start_time\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"%s: %.1f%% (std: %.3f), runtime: %.1fs\" % (name, cv_results.mean() * 100, cv_results.std(), run_time))\n",
    "    \n",
    "# Based on the obtained accuracy results and algorithms runtimes, for further tunning I recommend such algorithms:\n",
    "# [1]Logistic Regression, [2]k-Nearest Neighbors, [3]Gaussian Naive Bayes and possibly [4]Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97044/97044 [==============================] - 5s 49us/step - loss: 0.4226 - acc: 0.9019\n",
      "Epoch 2/10\n",
      "97044/97044 [==============================] - 1s 15us/step - loss: 0.1221 - acc: 0.9501\n",
      "Epoch 3/10\n",
      "97044/97044 [==============================] - 2s 17us/step - loss: 0.0643 - acc: 0.9824\n",
      "Epoch 4/10\n",
      "97044/97044 [==============================] - 2s 17us/step - loss: 0.0433 - acc: 0.9871\n",
      "Epoch 5/10\n",
      "97044/97044 [==============================] - 1s 15us/step - loss: 0.0353 - acc: 0.9891\n",
      "Epoch 6/10\n",
      "97044/97044 [==============================] - 1s 15us/step - loss: 0.0313 - acc: 0.9906\n",
      "Epoch 7/10\n",
      "97044/97044 [==============================] - 2s 17us/step - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 8/10\n",
      "97044/97044 [==============================] - 2s 17us/step - loss: 0.0274 - acc: 0.9928\n",
      "Epoch 9/10\n",
      "97044/97044 [==============================] - 2s 17us/step - loss: 0.0263 - acc: 0.9931\n",
      "Epoch 10/10\n",
      "97044/97044 [==============================] - 1s 15us/step - loss: 0.0254 - acc: 0.9935\n",
      "97044/97044 [==============================] - 5s 48us/step\n",
      "\n",
      "acc: 99.37%\n"
     ]
    }
   ],
   "source": [
    "### LIUTAURAS VILDA - Exploring and selecting ML algorithms ###\n",
    "\n",
    "# Neural Network Algorithm assessment\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "numpy.random.seed(7)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=20, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(univariate_selection_normalized_data_result, output_data, epochs=10, batch_size=300)\n",
    "\n",
    "scores = model.evaluate(univariate_selection_normalized_data_result, output_data)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# Due to this algorithm's provisional accuracy of 99.37%, it seems to be a good candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NELLA - Refining algorithms ###\n",
    "\n",
    "# For tuning part we are working on: DecisionTreeClassifier, GaussianNB, and one of Neural Network algorithm\n",
    "# This part is DecisionTreeClassifier tuning\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import linspace\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "\n",
    "print()\n",
    "print(\"With MAX Depths\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "max_depths = linspace(1, 11, 11, endpoint=True)\n",
    "\n",
    "for depth in max_depths:\n",
    "    decision_tree_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=depth,\n",
    "     max_features=None, max_leaf_nodes=None,\n",
    "     min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "     presort=False, random_state=None, splitter='best')\n",
    "\n",
    "    decision_tree_model.fit(univariate_selection_normalized_data_result, output_data)\n",
    "    output_prediction = decision_tree_model.predict(univariate_selection_normalized_data_result)\n",
    "\n",
    "    matrix = confusion_matrix(output_data, output_prediction)\n",
    "    print()\n",
    "    print(\"with: \" + str(depth))\n",
    "    print(matrix)\n",
    "    print()\n",
    "    cv_results = cross_val_score(decision_tree_model, univariate_selection_normalized_data_result, output_data, cv=kfold, scoring=scoring)\n",
    "    print(cv_results.mean())\n",
    "    print(\"-----------\")\n",
    "\n",
    "print()\n",
    "print(\"With MIN Sample Split\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "min_samples_splits = linspace(2, 11, 10, endpoint=True)\n",
    "\n",
    "for sample_split in min_samples_splits:\n",
    "    decision_tree_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
    "     max_features=None, max_leaf_nodes=None,\n",
    "     min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "     min_samples_split=int(sample_split), min_weight_fraction_leaf=0.0,\n",
    "     presort=False, random_state=None, splitter='best')\n",
    "\n",
    "    decision_tree_model.fit(univariate_selection_normalized_data_result, output_data)\n",
    "    output_prediction = decision_tree_model.predict(univariate_selection_normalized_data_result)\n",
    "\n",
    "    matrix = confusion_matrix(output_data, output_prediction)\n",
    "    print(\"with: \" + str(sample_split))\n",
    "    print(matrix)\n",
    "    print()\n",
    "    cv_results = cross_val_score(decision_tree_model, univariate_selection_normalized_data_result, output_data, cv=kfold, scoring=scoring)\n",
    "    print(cv_results.mean())\n",
    "    print(\"-----------\")\n",
    "\n",
    "print()\n",
    "print(\"With MIN Sample Leafs\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "min_samples_leafs = linspace(0.1, 0.5, 5, endpoint=True)\n",
    "\n",
    "for sample_leaf in min_samples_leafs:\n",
    "    decision_tree_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
    "     max_features=None, max_leaf_nodes=None,\n",
    "     min_impurity_decrease=1e-07, min_samples_leaf=sample_leaf,\n",
    "     min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
    "     presort=False, random_state=None, splitter='best')\n",
    "\n",
    "    decision_tree_model.fit(univariate_selection_normalized_data_result, output_data)\n",
    "    output_prediction = decision_tree_model.predict(univariate_selection_normalized_data_result)\n",
    "\n",
    "    matrix = confusion_matrix(output_data, output_prediction)\n",
    "    print(\"with: \" + str(sample_leaf))\n",
    "    print(matrix)\n",
    "    print()\n",
    "    cv_results = cross_val_score(decision_tree_model, univariate_selection_normalized_data_result, output_data, cv=kfold, scoring=scoring)\n",
    "    print(cv_results.mean())\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NELLA - Refining algorithms ###\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=20, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 8\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "final_model = KerasClassifier(build_fn=create_model, epochs=8, batch_size=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to build model: 11.63680100440979\n"
     ]
    }
   ],
   "source": [
    "### JO - Evaluating model and analysing the results ###\n",
    "\n",
    "# Import and separate test data, fit model and make prediction using selected models\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pandas import read_csv\n",
    "import time\n",
    "\n",
    "filename = 'datasets/test_imperson_without4n7_balanced_data.csv'\n",
    "# Read data removing the first row that is a header as numbers\n",
    "data = read_csv(filename, header=None, skiprows=1)\n",
    "\n",
    "# Separate input and target data\n",
    "test_data = data.values\n",
    "input_test_data = test_data[:,0:152]\n",
    "output_test_data = test_data[:,152]\n",
    "\n",
    "test = select_k_best.fit(input_test_data, output_test_data)\n",
    "# Transform test data using preferred feature selection method\n",
    "input_test_data_fs = test.transform(input_test_data)\n",
    "\n",
    "# Use selected model to make predictions on input test data \n",
    "start_time = time.time()\n",
    "final_model.fit(univariate_selection_normalized_data_result, output_data)\n",
    "run_time = time.time() - start_time\n",
    "predicted = final_model.predict(input_test_data_fs)\n",
    "\n",
    "print('Time taken to build model: ' + str(run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649882962298919\n"
     ]
    }
   ],
   "source": [
    "### JO - Evaluating model and analysing the results ###\n",
    "\n",
    "# Evaluate using Classification Accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(output_test_data, predicted)\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18702  1377]\n",
      " [   29 20050]]\n"
     ]
    }
   ],
   "source": [
    "### JO - Evaluating model and analysing the results ###\n",
    "\n",
    "# Evaluate using Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(output_test_data, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96     20079\n",
      "         1.0       0.94      1.00      0.97     20079\n",
      "\n",
      "    accuracy                           0.96     40158\n",
      "   macro avg       0.97      0.96      0.96     40158\n",
      "weighted avg       0.97      0.96      0.96     40158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### JO - Evaluating model and analysing the results ###\n",
    "\n",
    "# Evaluate using Classification Report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(output_test_data, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews correlation coefficient: 0.9320794446121159\n"
     ]
    }
   ],
   "source": [
    "### JO - Evaluating model and analysing the results ###\n",
    "\n",
    "# Compute Matthews correlation coefficient\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "mcc = matthews_corrcoef(output_test_data, predicted)\n",
    "print('Matthews correlation coefficient: ' + str(mcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
